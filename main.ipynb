{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notebooks/main.ipynb\n",
    "**Mục tiêu:** đây là notebook entry-point (demo / quick-start) cho repo.\n",
    "Nội dung hướng dẫn cách chạy lần lượt các script trong `src/` (nhớ rằng các file `.py` của bạn đều nằm trong `src/` và `config.py` đang ở ngoài `src/` ở thư mục gốc của repo).\n",
    "**Ghi chú:** chạy các ô theo thứ tự; một vài ô gọi trực tiếp các script trong `src/` (bằng lệnh `!python ...`), ô \"Quick demo\" sẽ chạy một bản demo nhẹ (không thay thế cho full-training scripts trong `src/`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Setup môi trường trong notebook (chạy từ thư mục notebooks/)\n",
    "import os, sys\n",
    "# Chuyển cwd về repo root (giả sử notebook nằm trong notebooks/)\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "print('Detected repo_root:', repo_root)\n",
    "os.chdir(repo_root)\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "print('Current working directory:', os.getcwd())\n",
    "print('Python sys.path[0] =', sys.path[0])\n",
    "\n",
    "# Nếu bạn chạy notebook trực tiếp từ repo root, ô trên vẫn an toàn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) (Tùy chọn) Cài dependencies\n",
    "Nếu bạn dùng Colab hoặc môi trường mới, hãy uncomment và sửa `requirements.txt` hoặc cài tay các package cần thiết. Các script trong `src/` dùng: `pandas`, `numpy`, `sentence-transformers`, `xgboost`, `scikit-learn`, `joblib`, `matplotlib`, `seaborn`, `nltk`, `torch`...\n",
    "Bạn có thể chạy cell bên dưới để cài nhanh (nếu cần)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt\n",
    "# ví dụ (bỏ dấu # để chạy):\n",
    "# !pip install pandas numpy sentence-transformers xgboost scikit-learn joblib matplotlib seaborn nltk torch tqdm\n",
    "\n",
    "# Nếu bạn dùng Colab và muốn mount Google Drive, thực hiện ở đây.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Kiểm tra GPU (với script có sẵn)\n",
    "Chạy file `src/GPU_check.py` để biết GPU có sẵn hay không."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chạy script kiểm tra GPU\n",
    "!python src/GPU_check.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Data cleaning (script `2.1_data_clean.py`)\n",
    "Chạy script dọn dữ liệu — nó đọc `config.RAW_DATA_PATH` và lưu `config.CLEAN_DATA_PATH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chạy data cleaning (lưu ý: config.py phải trỏ đúng đường dẫn ở trên máy bạn)\n",
    "!python src/2.1_data_clean.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Data augmentation (script `2.2_data_augmentation.py`)\n",
    "Script này sẽ đọc `config.CLEAN_DATA_PATH` và ghi `config.FINAL_DATA_PATH`.\n",
    "**Ghi chú:** script dùng `nltk` để augment — nếu chưa có, nó sẽ cố tải các gói cần thiết (có thể mất thời gian)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chạy augmentation\n",
    "!python src/2.2_data_augmentation.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Khám phá nhanh dữ liệu (script `1_view_data.py`)\n",
    "Script sẽ tạo các ảnh EDA (saves .png) để bạn kiểm tra phân phối nhãn và độ dài văn bản."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chạy EDA view\n",
    "!python src/1_view_data.py\n",
    "print('EDA images saved to current working directory (look for PNG files).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Quick demo: tính embedding + train XGBoost nhỏ (chạy nhanh, dùng để kiểm tra pipeline)\n",
    "**Lưu ý:** Đây là bản demo rút gọn để bạn test notebook — không thay thế scripts full training trong `src/` (3.1 / 3.2).\n",
    "Nếu muốn chạy full training, dùng `!python src/3.2_training_multi.py` hoặc `!python src/3.1_training_binary.py` theo nhu cầu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick demo: sample nhỏ, encode bằng SentenceTransformer và train XGBoost nhẹ\n",
    "import config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Đọc file đã xử lý (do 2.2 tạo ra)\n",
    "df = pd.read_csv(config.FINAL_DATA_PATH).dropna(subset=['type','posts'])\n",
    "n_samples = min(400, len(df))\n",
    "print(f'Dataset size after augment: {len(df)}; using {n_samples} rows for quick demo')\n",
    "df = df.sample(n=n_samples, random_state=42)\n",
    "X_texts = df['posts'].astype(str).tolist()\n",
    "y = df['type'].astype('category').cat.codes.values\n",
    "label_names = list(df['type'].astype('category').cat.categories)\n",
    "\n",
    "# Load embedder (device sẽ tự chọn; nếu muốn ép dùng CPU/GPU, sửa device)\n",
    "device = 'cuda' if __import__('torch').cuda.is_available() else 'cpu'\n",
    "print('Using device for embedder:', device)\n",
    "embedder = SentenceTransformer(config.MODEL_NAME, device=device)\n",
    "\n",
    "def encode_posts(posts):\n",
    "    parts = posts.split('|||')\n",
    "    emb = embedder.encode(parts, convert_to_numpy=True, batch_size=config.BATCH_SIZE, show_progress_bar=False)\n",
    "    return emb.mean(axis=0)\n",
    "\n",
    "# Encode (this may take a little time depending on samples)\n",
    "X_emb = np.array([encode_posts(p) for p in X_texts])\n",
    "\n",
    "# Quick train/test split and a tiny XGBoost (lightweight)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_emb, y, test_size=0.2, random_state=42, stratify=y)\n",
    "clf = xgb.XGBClassifier(objective='multi:softmax', num_class=len(label_names), n_estimators=50, max_depth=4, use_label_encoder=False, eval_metric='mlogloss')\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print('Quick demo accuracy:', accuracy_score(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) (Tuỳ chọn) Chạy full training hoặc evaluation scripts từ `src/`\n",
    "Nếu bạn muốn chạy full multiclass training (cẩn thận: lâu, cần nhiều tài nguyên):\n",
    "```bash\n",
    "# multiclass full training (chạy từ repo root)\n",
    "python src/3.2_training_multi.py\n",
    "# binary training (4 models)\n",
    "python src/3.1_training_binary.py\n",
    "# evaluation scripts\n",
    "python src/4.1_evaBIN.py\n",
    "python src/4.2_evaMUL.py\n",
    "```\n",
    "Các script sẽ lưu kết quả vào các folder được định nghĩa trong `config.py` (`OUTPUT_DIR_BINARY`, `OUTPUT_DIR_MULTICLASS`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Lời khuyên khi dùng notebook này\n",
    "- Đảm bảo `config.py` trỏ đúng đường dẫn dữ liệu (`RAW_DATA_PATH`, `CLEAN_DATA_PATH`, `FINAL_DATA_PATH`).\n",
    "- Nếu chạy trên Colab: mount Google Drive và sửa `config.py` hoặc set các biến môi trường tương ứng.\n",
    "- Full training cần GPU và thời gian — dùng `Quick demo` để kiểm tra pipeline trước.\n",
    "- Nếu bạn muốn mình convert notebook này thành file `.ipynb` tải về trực tiếp, báo mình — mình sẽ xuất file để bạn download.\n"
   ]
  }
 ]
}