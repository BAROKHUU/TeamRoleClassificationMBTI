# MBTI Personality Classification (NLP + XGBoost)

This project develops a system for classifying **MBTI personality types** based on textual posts, using:
- **Data preprocessing** (cleaning + augmentation)
- **Sentence Transformers** for embedding generation
- **XGBoost** for training and evaluation  (both binary & multiclass)
```
MBTI_project/
‚îÇ
‚îú‚îÄ‚îÄ data/                 # Contains raw, cleaned, and augmented datasets
‚îÇ   ‚îú‚îÄ‚îÄ mbti_1.csv
‚îÇ   ‚îú‚îÄ‚îÄ mbti_clean.csv
‚îÇ   ‚îî‚îÄ‚îÄ mbti_1_augmentednclean.csv
‚îÇ
‚îú‚îÄ‚îÄ sbert_all-MiniLM-L6-v2/ # Stores the pre-trained Sentence Transformer model
‚îÇ
‚îú‚îÄ‚îÄ src/                  # Main source code
‚îÇ   ‚îú‚îÄ‚îÄ 1_view_data.py
‚îÇ   ‚îú‚îÄ‚îÄ 2.1_data_clean.py
‚îÇ   ‚îú‚îÄ‚îÄ 2.2_data_augmentation.py
‚îÇ   ‚îú‚îÄ‚îÄ 3.1_training_binary.py
‚îÇ   ‚îú‚îÄ‚îÄ 3.2_training_XGBoost.py
‚îÇ   ‚îú‚îÄ‚îÄ 4.1_evaBIN.py
‚îÇ   ‚îú‚îÄ‚îÄ 4.2_evaMUL.py
‚îÇ   ‚îú‚îÄ‚îÄ binary_model/       # Stores trained binary classification models (.joblib) and reports (.json)
‚îÇ   ‚îî‚îÄ‚îÄ multiclass_model/   # Stores trained multi-class model and evaluation results
‚îÇ
‚îú‚îÄ‚îÄ config.py             # Configuration variables (paths, parameters)
‚îú‚îÄ‚îÄ demo.ipynb            # Jupyter Notebook for the Gradio-based interactive demo
‚îú‚îÄ‚îÄ requirements.txt      # List of Python dependencies
‚îî‚îÄ‚îÄ README.md             # Project documentation
```

Pretrained Model --> .joblib \n

Summary --> .json


## ‚öôÔ∏è Environment Setup

### 1. Clone repo + Setup
```bash
git clone https://github.com/BAROKHUU/TeamRoleClassificationMBTI.git
cd MBTI_project
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows

pip install -r requirements.txt
```
## üöÄ How to Run the Code
1. Prepare the dataset
Place the original file mbti_1.csv inside the data/ directory.
This file will be processed into multiple versions during execution.


2. Data Filtering
```bash
python src/2.1_data_clean.py
```
Input: data/mbti_1.csv
Output: data/mbti_clean.csv


3. Data Augmentation
```bash
python src/2.2_data_augmentation.py
```
Input: data/mbti_clean.csv
Output: data/mbti_1_augmentednclean.csv


4. Training

4.1. Binary classification
```bash
python src/3.1_training_binary.py
```
Output: Model XGBoost Binary inside the binary_model/ directory.

4.2. Multiclass classification 
```bash
Run: python src/3.2_training_XGBoost.py
```
Output: Model XGBoost Multiclass inside the multiclass_model/ directory.


5. Evaluation

5.1. Logistic Regression baseline (binary)
```bash
python src/4.1_evaBIN.py
```
Output: binary_model/primary_mbti_clf.joblib + confusion matrix + report JSON

5.2. XGBoost multiclass evaluation
```bash
python src/4.2_evaXGB.py
```
Output: multiclass_model/confusion_matrix_test.png + classification report


6. Demo Inference
```bash
jupyter notebook demo.ipynb # http://127.0.0.1:7860
```
Open Jupyter notebook and run demo UI through Gradio.